base_uri <- "https://api.github.com"
# URI variables (if any)
username <- "info201"
# The specific endpoint
resource <- paste0("/users/", username, "/repos")
# The complete URI
uri <- paste0(base_uri, resource)
uri
# Install `httr` package
# Only needs to be done once per machine!
install.packages("httr")
# Load the package (tell R functions are available for use)
library("httr")
# Load the package (tell R functions are available for use)
library("httr")
GET("https://ischool.uw.edu/")
# GET request to search google
query_params <- list(q = "informatics")
GET("https://www.google.com/search", query = query_params)
GET(uri)
base_uri <- "https://api.github.com"
# URI variables (if any)
username <- "Johnreese212"
# The specific endpoint
resource <- paste0("/users/", username, "/repos")
# The complete URI
uri <- paste0(base_uri, resource)
uri
GET(uri)
base_uri <- "https://api.github.com"
# URI variables (if any)
username <- "joelross"
# The specific endpoint
resource <- paste0("/users/", username, "/repos")
# The complete URI
uri <- paste0(base_uri, resource)
uri
source('~/.active-rstudio-document', echo=TRUE)
# The base URI
base_uri <- "https://api.github.com"
# URI variables (if any)
username <- "joelross"
# The specific endpoint
resource <- paste0("/users/", username, "/repos")
# The complete URI
uri <- paste0(base_uri, resource)
uri
# Install `httr` package
# Only needs to be done once per machine!
install.packages("httr")
# Load the package (tell R functions are available for use)
library("httr")
# GET request to search google
query_params <- list(q = "informatics")
GET("https://www.google.com/search", query = query_params)
GET(uri)
# The complete URI
uri <- paste0(base_uri, resource)
# The base URI
base_uri <- "https://api.github.com"
# URI variables (if any)
username <- "joelross"
# The specific endpoint
resource <- paste0("/users/", username, "/repos")
# The complete URI
uri <- paste0(base_uri, resource)
GET(uri)
install.packages("jsonlite") # once per machine
library("jsonlite")
# Make a request to a given `uri` with a set of `query_params`
# Then extract and parse the results
# Make the request
response <- GET(uri, query = query_params)
# Extract the content of the response
response_text <- content(response, "text")
# Convert the JSON string to a list
response_data <- fromJSON(response_text)
View(response_data)
# Check: is it a data frame already?
is.data.frame(response_data) # FALSE
# Inspect the data!
str(response_data) # view as a formatted string
names(response_data) # "href" "items" "limit" "next" "offset" "previous" "total"
# Extract the (useful) data
items <- response_data$items # extract from the list
is.data.frame(items) # TRUE; you can work with that!
# Create a `people` data frame with a `names` column
people <- data.frame(names = c("Ed", "Jessica", "Keagan"))
# Create a data frame of favorites with two columns
favorites <- data.frame(
food = c("Pizza", "Pasta", "Salad"),
music = c("Bluegrass", "Indie", "Electronic")
)
# Store the second data frame as a column of the first -- A BAD IDEA
people$favorites <- favorites # the `favorites` column is a data frame!
# This prints nicely, but is misleading
print(people)
# Despite what RStudio prints, there is not actually a column `favorites.food`
people$favorites.food # NULL
# Access the `food` column of the data frame stored in `people$favorites`
people$favorites$food # [1] Pizza Pasta Salad
# Use `flatten()` to format nested data frames
people <- flatten(people)
people$favorites.food # this just got created! Woo!
# Load the httr and jsonlite libraries for accessing data
# You can also load `dplyr` if you wish to use it
library("httr")
library("jsonlite")
library("dplyr")
library("httr")
library("jsonlite")
library("dplyr")
# Create a variable base_uri that stores the base URI (as a string) for the
# Github API (https://api.github.com)
base_uri <- "https://api.github.com"
# Send a GET request to this endpoint (the `base_uri` followed by the
# `org_resource` path). Print the response to show that your request worked.
# (The listed URI will also allow you to inspect the JSON in the browser easily).
print(GET(paste0(base_uri, org_resource)))
# Under the "Repositories" category of the API documentation, find the endpoint
# that will list _repos in an organization_. Then create a variable named
# `org_resource` that stores the endpoint for the `programming-for-data-science`
# organization repos (this is the _path_ to the resource of interest).
org_resource <- "/orgs/programming-for-data-science/repos"
# Send a GET request to this endpoint (the `base_uri` followed by the
# `org_resource` path). Print the response to show that your request worked.
# (The listed URI will also allow you to inspect the JSON in the browser easily).
print(GET(paste0(base_uri, org_resource)))
# Extract the content of the response using the `content()` function, saving it
# in a variable.
resources_content <- content(paste0(base_uri, org_resource), type = "text")
# Extract the content of the response using the `content()` function, saving it
# in a variable.
resources_content <- content(paste0(base_uri, org_resource), type = "text")
# Send a GET request to this endpoint (the `base_uri` followed by the
# `org_resource` path). Print the response to show that your request worked.
# (The listed URI will also allow you to inspect the JSON in the browser easily).
base_endpoint <- GET(paste0(base_uri, org_resource))
print(base_endpoint)
# Extract the content of the response using the `content()` function, saving it
# in a variable.
resources_content <- content(base_endpoint, type = "text")
# Convert the content variable from a JSON string into a data frame.
resources_data <- fromJSON(resources_content)
# How many (public) repositories does the organization have?
nrow(resources_content)
# How many (public) repositories does the organization have?
nrow(resources_data)
View(resources_data)
# Search queries require a query parameter (for what to search for). Create a
# `query_params` list variable that specifies an appropriate key and value for
# the search term (you can search for anything you want!)
query_params <- list(q = "soccer")
search_endpoint <- "/search/repositories?"
# Send a GET request to the `search_endpoint`--including your params list as the
# `query`. Print the response to show that your request worked.
search_request <- GET(paste0(base_uri, search_endpoint), query = query_params)
# Extract the content of the response and convert it from a JSON string into a
# data frame.
search_content <- content(search_request, type = "text")
search_data <- fromJSON(search_content)
search_data <- fromJSON(search_content)
is.data.frame(search_data)
?fromJSON()
# Extract the content of the response and convert it from a JSON string into a
# data frame.
search_content <- content(search_request, "text")
search_data <- fromJSON(search_content)
# Search queries require a query parameter (for what to search for). Create a
# `query_params` list variable that specifies an appropriate key and value for
# the search term (you can search for anything you want!)
query_params <- list(q = "FIFA")
# Send a GET request to the `search_endpoint`--including your params list as the
# `query`. Print the response to show that your request worked.
search_request <- GET(paste0(base_uri, search_endpoint), query = query_params)
# Extract the content of the response and convert it from a JSON string into a
# data frame.
search_content <- content(search_request, "text")
search_data <- fromJSON(search_content)
View(search_data)
str(search_data)
items <- search_data$items
View(items)
# How many search repos did your search find? (Hint: check the list names to
# find an appropriate value).
names(items)
# How many search repos did your search find? (Hint: check the list names to
# find an appropriate value).
nrow(items)
# What are the full names of the top 5 repos in the search results?
items$full_name
library(hflights)
library(dplyr)
library(hflights)
library(flights)
library(dplyr)
library(flights)
data(flights)
library(nycflights13)
library(flights)
df <- data.frame(flights)
View(df)
df %>%
filter(origin == "SEA")
df %>%
filter(origin == "SEA") %>%
View()
df %>%
unique(origin)
df %>%
unique(df$origin)
df %>%
group_by(origin)
df %>%
group_by(origin) %>%
View()
df %>%
filter(dest == "SEA")
df %>%
filter(dest == "SEA") %>%
View()
df %>%
filter(dest == "SEA") %>%
order(arr_delay) %>%
head()
df %>%
filter(dest == "SEA") %>%
arrange(arr_delay)
df %>%
filter(dest == "SEA") %>%
arrange(arr_delay) %>%
View()
iris.sepal.length.greater.than.five <- select(iris, sepal.length > 5)
iris
View(iris)
iris.sepal.length.greater.than.five <- select(iris, Sepal.length > 5)
iris.sepal.length.greater.than.five <- select(iris, Sepal.Length > 5)
iris.sepal.length.greater.than.five <- select(iris, iris$Sepal.Length > 5)
iris.sepal.length.greater.than.five <- iris %>%
filter(Sepal.Length > 5)
View(iris.sepal.length.greater.than.five)
iris.species.only.setosas <- filter(iris, species == "setosa")
iris.species.only.setosas <- filter(iris, iris$species == "setosa")
iris.species.only.setosas <- iris %>%
filter(species == "setosa")
iris.species.only.setosas <- iris %>%
filter(Species == "setosa")
iris.species.only.setosas
View(iris.species.only.setosas)
vec <- 1:100
install.packages("shiny")
library("shiny")
library("shiny")
shinyApp(ui = my_ui, server = my_server)
library("shiny")
# define a UI for the app
my_ui <- fluidPage(
h1("Hello Shiny"),
p("This is my first demo"),
textInput(inputId = "user_name", label="What is your name?")
) # make me a shiny UI
my_server <- function(input, output) {
# server does some stuff
}
shinyApp(ui = my_ui, server = my_server)
shinyApp(ui = my_ui, server = my_server)
shinyApp(ui = my_ui, server = my_server)
my_ui <- fluidPage(
h1("Hello Shiny"),
p("This is my first demo"),
textInput(inputId = "user_name", label="What is your name?"),
# creates a text box
textInput(inputId = "text_key", label = "Enter Text"),
# creates a slider
sliderInput(inputId = "slide_key", label = "Pick a number",
min = 1, max = 20, value = 12)
) # make me a shiny UI
my_server <- function(input, output) {
# server does some stuff
}
shinyApp(ui = my_ui, server = my_server)
shinyApp(ui = my_ui, server = my_server)
my_ui <- fluidPage(
h1("Hello Shiny"),
p("This is my first demo"),
textInput(inputId = "user_name", label="What is your name?"),
# creates a slider
sliderInput(inputId = "slide_key", label = "Pick a number",
min = 1, max = 20, value = 12)
) # make me a shiny UI
my_server <- function(input, output) {
# server does some stuff
}
shinyApp(ui = my_ui, server = my_server)
shinyApp(ui = my_ui, server = my_server)
runApp('Desktop/GitHub/shiny-demo')
runApp('Desktop/GitHub/shiny-demo')
runApp('Desktop/GitHub/shiny-demo')
runApp('Desktop/GitHub/shiny-demo')
# Load the `shiny` package
library("shiny")
?numericInput
?textOutput
runApp('Desktop/GitHub/exercises-Johnreese212/chapter-19-exercises/exercise-2')
# Load the `shiny` package
library("shiny")
# Create a new `shinyApp()` using the above ui and server
shinyApp(ui = john_ui, server = john_server)
runApp('Desktop/GitHub/exercises-Johnreese212/chapter-19-exercises/exercise-2')
library("ggplot2")
runApp('Desktop/GitHub/shiny-demo')
library("dplyr")
runApp('Desktop/GitHub/shiny-demo')
runApp('Desktop/GitHub/shiny-demo')
runApp('Desktop/GitHub/shiny-demo')
runApp('Desktop/GitHub/shiny-demo')
setwd("~/Desktop/GitHub/INFO-201-Final-Project")
shiny::runApp()
setwd("~/Desktop/GitHub/a6-collaboration-Johnreese212")
#Load libraries
library(jsonlite)
library(httr)
library(dplyr)
library(stringr)
#Donald Trump's Twitter data from 2017
trump_tweets <- read_json("data/2017_trump_twitter.json", simplifyVector = TRUE)
trump_tweets <- trump_tweets %>%
select(created_at,
text,
retweet_count,
favorite_count,
is_retweet)
#Donald Trump's approval rating
trump_approval <- read.csv("data/approval_polllist.csv", stringsAsFactors = FALSE)
trump_approval <- trump_approval %>%
select(poll_id,
startdate,
enddate,
pollster,
grade,
samplesize,
approve,
disapprove,
url)
library(jsonlite)
library(httr)
library(dplyr)
library(stringr)
#Donald Trump's Twitter data from 2017
trump_tweets <- read_json("data/2017_trump_twitter.json", simplifyVector = TRUE)
trump_tweets <- trump_tweets %>%
select(created_at,
text,
retweet_count,
favorite_count,
is_retweet)
#Donald Trump's approval rating
trump_approval <- read.csv("data/approval_polllist.csv", stringsAsFactors = FALSE)
trump_approval <- trump_approval %>%
select(poll_id,
startdate,
enddate,
pollster,
grade,
samplesize,
approve,
disapprove,
url)
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate(
Date = as.Date(trimws(paste(substr(created_at,4, 10), "2017")), "%b %d %Y")
, num = 1
) %>%
group_by(Date) %>%
summarize(Frequency = sum(num))
View(trump_tweet_frequency)
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate_(
Date = as.Date(trimws(paste(substr(created_at,4, 10), "2017")), "%b %d %Y")
, num = 1
) %>%
group_by(Date) %>%
summarize_(Frequency = sum(num))
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate_(
Date = as.Date(trimws(paste(substr("created_at",4, 10), "2017")), "%b %d %Y")
, num = 1
) %>%
group_by(Date) %>%
summarize_(Frequency = sum(num))
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate_(
Date = as.Date(trimws(paste(substr("created_at",4, 10), "2017")), "%b %d %Y")
, "num" = 1
) %>%
group_by(Date) %>%
summarize_(Frequency = sum(num))
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate_(
Date = as.Date(trimws(paste(substr("created_at",4, 10), "2017")), "%b %d %Y")
, "num" = 1
) %>%
group_by("Date") %>%
summarize_(Frequency = sum("num"))
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate_(
Date = as.Date(trimws(paste(substr("created_at",4, 10), "2017")), "%b %d %Y")
, "num" = 1
) #%>%
View(trump_tweet_frequency)
detach("package:dplyr", unload=TRUE)
detach("package:plyr", unload=TRUE)
library(plyr)
library(jsonlite)
library(httr)
library(dplyr)
library(tidyr)
library(stringr)
#Donald Trump's Twitter data from 2017
trump_tweets <- read_json("data/2017_trump_twitter.json", simplifyVector = TRUE)
trump_tweets <- trump_tweets %>%
select(created_at,
text,
retweet_count,
favorite_count,
is_retweet)
#Donald Trump's approval rating
trump_approval <- read.csv("data/approval_polllist.csv", stringsAsFactors = FALSE)
trump_approval <- trump_approval %>%
select(poll_id,
startdate,
enddate,
pollster,
grade,
samplesize,
approve,
disapprove,
url)
summary_twitter <- trump_tweets %>%
summarize(
"Total Tweets" = nrow(trump_tweets),
"Tweets from Trump" = nrow(trump_tweets) - sum(is_retweet),
"Average Retweet Count" = round(mean(retweet_count), digits = 0),
"Average Favorite Count" = mean(favorite_count)
)
#General Averages
# Returns the most common value from data set -- adapted from https://www.tutorialspoint.com/r/r_mean_median_mode.htm
find_mode <- function(data) {
unique <- unique(data)
unique[which.max(tabulate(match(data, unique)))]
}
average_tweets <-mean(trump_tweets$retweet_count)
pollsters <- as.data.frame(unique(trump_approval$pollster))
summary_approval <- trump_approval %>%
summarize(
"Total Pollsters" = nrow(pollsters),
"Most Common Grade" = find_mode(grade),
"Average Approval" = round(mean(approve), digits = 1),
"Max Approval" = round(max(approve), digits = 1),
"Min Approval" = round(min(approve), digits = 1),
"Standard Deviation of Approval" = round(sd(approve), digits = 1),
"Average Disapproval" = round(mean(disapprove), digits = 1),
"Max Dissapproval" = round(max(disapprove), digits = 1),
"Min Dissapproval" = round(min(disapprove), digits = 1),
"Standard Deviation of Dissapproval" = round(sd(disapprove), digits = 1)
)
#Answering critical question #1
trump_tweets_russia <- filter(trump_tweets, str_detect(trump_tweets$text, "Russia"))
trump_tweets_russia <- head(trump_tweets_russia, 5)
trump_tweets_russia <- trump_tweets_russia %>%
select("Date" = created_at,
"Tweet" = text,
"Is A Retweet" = is_retweet,
"Retweets" = retweet_count,
"Favorites" = favorite_count) %>%
head(5)
#Answering critical question #3
trump_tweets_democrats<- filter(trump_tweets, str_detect(trump_tweets$text, "Democrat"))
trump_tweets_democrats<- head(trump_tweets_democrats, 5)
trump_tweets_democrats <- trump_tweets_democrats %>%
select("Date" = created_at,
"Tweet" = text,
"Is A Retweet" = is_retweet,
"Retweets" = retweet_count,
"Favorites" = favorite_count) %>%
head(5)
average_12_31<- trump_approval[1343:1345,]
average_12_31<- mean(average_12_31$approve)
print(average_12_31)
#Answering critical question #2
trump_origin_tweets <- filter(trump_tweets, is_retweet == FALSE)
words <- tolower(paste(trump_origin_tweets$text, collapse=" "))
word_list <- strsplit(words, " ")
sorted_words <- sort(table(word_list), decreasing = TRUE)
top_100_words <- head(as.data.frame(sorted_words), 100)
# A data frame representing the number of daily tweets during 2017 by President Trump
trump_tweet_frequency <- trump_tweets %>%
mutate(
Date = as.Date(trimws(paste(substr(created_at,4, 10), "2017")), "%b %d %Y")
, num = 1
) %>%
group_by(Date) %>%
summarize(Frequency = sum(num))
setwd("~/Desktop/GitHub/INFO-201-Final-Project")
runApp()
runApp()
